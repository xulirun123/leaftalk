/**
 * åª’ä½“è®¾å¤‡ç®¡ç†æœåŠ¡
 * å¤„ç†éŸ³è§†é¢‘è®¾å¤‡è®¿é—®ã€åª’ä½“æµé‡‡é›†å’Œç®¡ç†
 */

export interface MediaDevice {
  deviceId: string
  label: string
  kind: 'audioinput' | 'audiooutput' | 'videoinput'
}

export interface MediaConstraints {
  audio?: boolean | MediaTrackConstraints
  video?: boolean | MediaTrackConstraints
}

export interface MediaQuality {
  level: 'low' | 'medium' | 'high' | 'ultra'
  video: {
    width: number
    height: number
    frameRate: number
    bitrate: number
  }
  audio: {
    sampleRate: number
    bitrate: number
  }
}

class MediaService {
  private currentStream: MediaStream | null = null
  private devices: MediaDevice[] = []
  private currentVideoDevice: string | null = null
  private currentAudioDevice: string | null = null
  private isInitialized = false
  private requestCounter = 0
  private activeRequestId = 0

  // é¢„å®šä¹‰çš„è´¨é‡é…ç½®
  private qualityPresets: Record<string, MediaQuality> = {
    low: {
      level: 'low',
      video: { width: 320, height: 240, frameRate: 15, bitrate: 200000 },
      audio: { sampleRate: 16000, bitrate: 32000 }
    },
    medium: {
      level: 'medium',
      video: { width: 640, height: 480, frameRate: 24, bitrate: 500000 },
      audio: { sampleRate: 44100, bitrate: 64000 }
    },
    high: {
      level: 'high',
      video: { width: 1280, height: 720, frameRate: 30, bitrate: 1000000 },
      audio: { sampleRate: 48000, bitrate: 128000 }
    },
    ultra: {
      level: 'ultra',
      video: { width: 1920, height: 1080, frameRate: 30, bitrate: 2000000 },
      audio: { sampleRate: 48000, bitrate: 128000 }
    }
  }

  /**
   * åˆå§‹åŒ–åª’ä½“æœåŠ¡
   */
  async initialize(): Promise<void> {
    try {
      console.log('ğŸ¥ åˆå§‹åŒ–åª’ä½“æœåŠ¡...')

      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('æµè§ˆå™¨ä¸æ”¯æŒ WebRTC')
      }

      // æšä¸¾è®¾å¤‡
      await this.enumerateDevices()

      this.isInitialized = true
      console.log('âœ… åª’ä½“æœåŠ¡åˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      console.error('âŒ åª’ä½“æœåŠ¡åˆå§‹åŒ–å¤±è´¥:', error)
      throw error
    }
  }

  /**
   * æšä¸¾å¯ç”¨çš„åª’ä½“è®¾å¤‡
   */
  async enumerateDevices(): Promise<MediaDevice[]> {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices()

      this.devices = devices
        .filter(device => device.kind !== 'audiooutput' || device.deviceId !== 'default')
        .map(device => ({
          deviceId: device.deviceId,
          label: device.label || this.getDefaultDeviceLabel(device.kind),
          kind: device.kind as 'audioinput' | 'audiooutput' | 'videoinput'
        }))

      console.log('ğŸ“± å‘ç°è®¾å¤‡:', this.devices.length, 'ä¸ª')
      console.log('ğŸ“± è®¾å¤‡åˆ—è¡¨:', this.devices)

      return this.devices
    } catch (error) {
      console.error('âŒ æšä¸¾è®¾å¤‡å¤±è´¥:', error)
      return []
    }
  }

  /**
   * è·å–é»˜è®¤è®¾å¤‡æ ‡ç­¾
   */
  private getDefaultDeviceLabel(kind: string): string {
    switch (kind) {
      case 'audioinput': return 'é»˜è®¤éº¦å…‹é£'
      case 'audiooutput': return 'é»˜è®¤æ‰¬å£°å™¨'
      case 'videoinput': return 'é»˜è®¤æ‘„åƒå¤´'
      default: return 'æœªçŸ¥è®¾å¤‡'
    }
  }

  /**
   * è·å–ç”¨æˆ·åª’ä½“æµï¼ˆæ¸è¿›å¼é™çº§ï¼‰
   */
  async getUserMedia(constraints: MediaConstraints): Promise<MediaStream> {
    try {
      console.log('ğŸ¥ è¯·æ±‚ç”¨æˆ·åª’ä½“:', constraints)

      // å°è¯•è·å–å®Œæ•´åª’ä½“æµ
      let stream = await this.tryGetUserMedia(constraints)

      if (stream) {
        this.currentStream = stream
        this.setupStreamEventListeners(stream)
        console.log('âœ… åª’ä½“æµè·å–æˆåŠŸ')
        return stream
      }

      throw new Error('æ— æ³•è·å–åª’ä½“æµ')
    } catch (error) {
      console.error('âŒ è·å–ç”¨æˆ·åª’ä½“å¤±è´¥:', error)
      throw error
    }
  }

  /**
   * å°è¯•è·å–ç”¨æˆ·åª’ä½“ï¼ˆå¸¦é™çº§ç­–ç•¥ + å¿«é€Ÿè¶…æ—¶å…œåº•ï¼‰
   */
  private async tryGetUserMedia(constraints: MediaConstraints): Promise<MediaStream | null> {
    const hasVideo = !!constraints.video

    // ä¼˜å…ˆå°è¯•â€œå¿«é€Ÿé¢„è§ˆâ€ä½æ¸…è§†é¢‘ï¼Œæå‡é¦–å¸§é€Ÿåº¦
    const fastVideo: MediaConstraints | null = hasVideo ? {
      audio: constraints.audio ?? true,
      video: {
        width: { ideal: 320, max: 640 },
        height: { ideal: 240, max: 480 },
        frameRate: { ideal: 15, max: 24 },
        facingMode: 'user'
      }
    } : null

    const attempts = [
      fastVideo,
      constraints,
      hasVideo ? {
        ...constraints,
        video: {
          width: { ideal: 640, max: 1280 },
          height: { ideal: 480, max: 720 },
          frameRate: { ideal: 24, max: 30 },
          facingMode: 'user'
        }
      } : null,
      hasVideo ? { audio: constraints.audio ?? true } : null,
      { audio: true }
    ].filter(Boolean) as MediaConstraints[]

    const requestId = ++this.requestCounter
    this.activeRequestId = requestId

    for (const attempt of attempts) {
      try {
        console.log('ğŸ”„ å°è¯•åª’ä½“çº¦æŸ:', attempt)
        const timeoutMs = attempt.video ? 1800 : 1200
        const stream = await this.getUserMediaWithTimeout(attempt, timeoutMs, requestId)
        if (!stream) { continue }
        console.log('âœ… åª’ä½“æµè·å–æˆåŠŸ:', {
          audio: stream.getAudioTracks().length,
          video: stream.getVideoTracks().length
        })
        return stream
      } catch (error) {
        console.warn('âš ï¸ åª’ä½“çº¦æŸå¤±è´¥:', attempt, error)
        continue
      }
    }

    return null
  }

  // å¸¦è¶…æ—¶ä¸å»¶è¿Ÿç»“æœä¸¢å¼ƒçš„ getUserMedia
  private async getUserMediaWithTimeout(attempt: MediaConstraints, timeoutMs: number, requestId: number): Promise<MediaStream | null> {
    let settled = false

    const timer = new Promise<null>((resolve) => {
      setTimeout(() => {
        if (!settled) {
          resolve(null)
        }
      }, timeoutMs)
    })

    const gum = navigator.mediaDevices.getUserMedia(attempt)
      .then(stream => {
        // å¦‚æœæ­¤æ—¶å·²ç»ä¸æ˜¯æœ€æ–°è¯·æ±‚ï¼Œä¸¢å¼ƒå¹¶å…³é—­è½¨é“
        if (this.activeRequestId !== requestId) {
          try { stream.getTracks().forEach(t => t.stop()) } catch {}
          return null
        }
        return stream
      })
      .catch(() => null)

    const result = await Promise.race([gum, timer])
    settled = true
    return result
  }

  /**
   * è®¾ç½®åª’ä½“æµäº‹ä»¶ç›‘å¬
   */
  private setupStreamEventListeners(stream: MediaStream): void {
    stream.getTracks().forEach(track => {
      track.addEventListener('ended', () => {
        console.log(`ğŸ“± åª’ä½“è½¨é“ç»“æŸ: ${track.kind}`)
      })

      track.addEventListener('mute', () => {
        console.log(`ğŸ”‡ åª’ä½“è½¨é“é™éŸ³: ${track.kind}`)
      })

      track.addEventListener('unmute', () => {
        console.log(`ğŸ”Š åª’ä½“è½¨é“å–æ¶ˆé™éŸ³: ${track.kind}`)
      })
    })
  }

  /**
   * æ ¹æ®è´¨é‡çº§åˆ«è·å–åª’ä½“çº¦æŸ
   */
  getConstraintsByQuality(quality: 'low' | 'medium' | 'high' | 'ultra', includeVideo = true): MediaConstraints {
    const preset = this.qualityPresets[quality]

    const constraints: MediaConstraints = {
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true,
        sampleRate: preset.audio.sampleRate
      }
    }

    if (includeVideo) {
      constraints.video = {
        width: { ideal: preset.video.width },
        height: { ideal: preset.video.height },
        frameRate: { ideal: preset.video.frameRate },
        facingMode: 'user'
      }
    }

    return constraints
  }

  /**
   * åˆ‡æ¢æ‘„åƒå¤´
   */
  async switchCamera(): Promise<MediaStream | null> {
    try {
      if (!this.currentStream) {
        throw new Error('å½“å‰æ²¡æœ‰æ´»è·ƒçš„åª’ä½“æµ')
      }

      const videoDevices = this.devices.filter(d => d.kind === 'videoinput')
      if (videoDevices.length < 2) {
        console.warn('âš ï¸ åªæœ‰ä¸€ä¸ªæ‘„åƒå¤´ï¼Œæ— æ³•åˆ‡æ¢')
        return this.currentStream
      }

      // æ‰¾åˆ°ä¸‹ä¸€ä¸ªæ‘„åƒå¤´
      const currentIndex = videoDevices.findIndex(d => d.deviceId === this.currentVideoDevice)
      const nextIndex = (currentIndex + 1) % videoDevices.length
      const nextDevice = videoDevices[nextIndex]

      console.log('ğŸ”„ åˆ‡æ¢æ‘„åƒå¤´:', nextDevice.label)

      // åœæ­¢å½“å‰è§†é¢‘è½¨é“
      const videoTracks = this.currentStream.getVideoTracks()
      videoTracks.forEach(track => track.stop())

      // è·å–æ–°çš„è§†é¢‘æµ
      const newVideoStream = await navigator.mediaDevices.getUserMedia({
        video: { deviceId: { exact: nextDevice.deviceId } }
      })

      // æ›¿æ¢è§†é¢‘è½¨é“
      const newVideoTrack = newVideoStream.getVideoTracks()[0]
      this.currentStream.removeTrack(videoTracks[0])
      this.currentStream.addTrack(newVideoTrack)

      this.currentVideoDevice = nextDevice.deviceId
      console.log('âœ… æ‘„åƒå¤´åˆ‡æ¢æˆåŠŸ')

      return this.currentStream
    } catch (error) {
      console.error('âŒ åˆ‡æ¢æ‘„åƒå¤´å¤±è´¥:', error)
      return null
    }
  }

  /**
   * åˆ‡æ¢éº¦å…‹é£
   */
  async switchMicrophone(deviceId?: string): Promise<MediaStream | null> {
    try {
      if (!this.currentStream) {
        throw new Error('å½“å‰æ²¡æœ‰æ´»è·ƒçš„åª’ä½“æµ')
      }

      const audioDevices = this.devices.filter(d => d.kind === 'audioinput')
      let targetDevice: MediaDevice

      if (deviceId) {
        const device = audioDevices.find(d => d.deviceId === deviceId)
        if (!device) {
          throw new Error('æŒ‡å®šçš„éŸ³é¢‘è®¾å¤‡ä¸å­˜åœ¨')
        }
        targetDevice = device
      } else {
        // è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªè®¾å¤‡
        const currentIndex = audioDevices.findIndex(d => d.deviceId === this.currentAudioDevice)
        const nextIndex = (currentIndex + 1) % audioDevices.length
        targetDevice = audioDevices[nextIndex]
      }

      console.log('ğŸ”„ åˆ‡æ¢éº¦å…‹é£:', targetDevice.label)

      // åœæ­¢å½“å‰éŸ³é¢‘è½¨é“
      const audioTracks = this.currentStream.getAudioTracks()
      audioTracks.forEach(track => track.stop())

      // è·å–æ–°çš„éŸ³é¢‘æµ
      const newAudioStream = await navigator.mediaDevices.getUserMedia({
        audio: { deviceId: { exact: targetDevice.deviceId } }
      })

      // æ›¿æ¢éŸ³é¢‘è½¨é“
      const newAudioTrack = newAudioStream.getAudioTracks()[0]
      this.currentStream.removeTrack(audioTracks[0])
      this.currentStream.addTrack(newAudioTrack)

      this.currentAudioDevice = targetDevice.deviceId
      console.log('âœ… éº¦å…‹é£åˆ‡æ¢æˆåŠŸ')

      return this.currentStream
    } catch (error) {
      console.error('âŒ åˆ‡æ¢éº¦å…‹é£å¤±è´¥:', error)
      return null
    }
  }

  /**
   * é™éŸ³/å–æ¶ˆé™éŸ³
   */
  toggleMute(): boolean {
    if (!this.currentStream) return false

    const audioTracks = this.currentStream.getAudioTracks()
    const isMuted = audioTracks.length > 0 && !audioTracks[0].enabled

    audioTracks.forEach(track => {
      track.enabled = isMuted
    })

    console.log(isMuted ? 'ğŸ”Š å–æ¶ˆé™éŸ³' : 'ğŸ”‡ é™éŸ³')
    return !isMuted
  }

  /**
   * å¼€å¯/å…³é—­è§†é¢‘
   */
  toggleVideo(): boolean {
    if (!this.currentStream) return false

    const videoTracks = this.currentStream.getVideoTracks()
    const isVideoOff = videoTracks.length > 0 && !videoTracks[0].enabled

    videoTracks.forEach(track => {
      track.enabled = isVideoOff
    })

    console.log(isVideoOff ? 'ğŸ“¹ å¼€å¯è§†é¢‘' : 'ğŸ“¹ å…³é—­è§†é¢‘')
    return !isVideoOff
  }

  /**
   * åœæ­¢å½“å‰åª’ä½“æµ
   */
  stopCurrentStream(): void {
    if (this.currentStream) {
      this.currentStream.getTracks().forEach(track => {
        track.stop()
      })
      this.currentStream = null
      console.log('ğŸ›‘ åª’ä½“æµå·²åœæ­¢')
    }
  }

  /**
   * è·å–å½“å‰åª’ä½“æµ
   */
  getCurrentStream(): MediaStream | null {
    return this.currentStream
  }

  /**
   * è·å–è®¾å¤‡åˆ—è¡¨
   */
  getDevices(): MediaDevice[] {
    return this.devices
  }

  /**
   * æ£€æŸ¥è®¾å¤‡æƒé™
   */
  async checkPermissions(): Promise<{ audio: boolean; video: boolean }> {
    try {
      const permissions = {
        audio: false,
        video: false
      }

      // æ£€æŸ¥éº¦å…‹é£æƒé™
      try {
        const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true })
        permissions.audio = true
        audioStream.getTracks().forEach(track => track.stop())
      } catch (error) {
        console.warn('âš ï¸ éº¦å…‹é£æƒé™è¢«æ‹’ç»')
      }

      // æ£€æŸ¥æ‘„åƒå¤´æƒé™
      try {
        const videoStream = await navigator.mediaDevices.getUserMedia({ video: true })
        permissions.video = true
        videoStream.getTracks().forEach(track => track.stop())
      } catch (error) {
        console.warn('âš ï¸ æ‘„åƒå¤´æƒé™è¢«æ‹’ç»')
      }

      return permissions
    } catch (error) {
      console.error('âŒ æ£€æŸ¥æƒé™å¤±è´¥:', error)
      return { audio: false, video: false }
    }
  }

  /**
   * è·å–åª’ä½“æµç»Ÿè®¡ä¿¡æ¯
   */
  getStreamStats(): { audio: any; video: any } | null {
    if (!this.currentStream) return null

    const audioTracks = this.currentStream.getAudioTracks()
    const videoTracks = this.currentStream.getVideoTracks()

    return {
      audio: audioTracks.length > 0 ? {
        enabled: audioTracks[0].enabled,
        label: audioTracks[0].label,
        settings: audioTracks[0].getSettings()
      } : null,
      video: videoTracks.length > 0 ? {
        enabled: videoTracks[0].enabled,
        label: videoTracks[0].label,
        settings: videoTracks[0].getSettings()
      } : null
    }
  }
}

// å¯¼å‡ºå•ä¾‹
export const mediaService = new MediaService()
export default mediaService
